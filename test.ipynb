{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip_modified\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from utils.model import getCLIP, getCAM\n",
    "from utils.preprocess import getImageTranform\n",
    "\n",
    "RESIZE = 1\n",
    "\n",
    "ImageTransform = getImageTranform(resize=RESIZE)\n",
    "originalTransform = getImageTranform(resize=RESIZE, normalized=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipcam(CLIP_MODEL_NAME, CAM_MODEL_NAME, images, sentence, DISTILL_NUM = 0, ATTACK = None, GPU_ID = 'cpu'):\n",
    "    \n",
    "    model, target_layer, reshape_transform = getCLIP(model_name=CLIP_MODEL_NAME, gpu_id=GPU_ID)\n",
    "    \n",
    "    cam = getCAM(model_name=CAM_MODEL_NAME, model=model, target_layer=target_layer, gpu_id=GPU_ID, reshape_transform=reshape_transform)\n",
    "    MASK_THRESHOLD = get_mask_threshold(CLIP_MODEL_NAME)\n",
    "    \n",
    "    final_img = get_clipcam_single(cam, model, MASK_THRESHOLD, images[0], sentence, DISTILL_NUM = DISTILL_NUM, ATTACK = ATTACK, GPU_ID = GPU_ID)\n",
    "\n",
    "    del cam\n",
    "    del model\n",
    "    return final_img\n",
    "\n",
    "def get_mask_threshold(CLIP_MODEL_NAME):\n",
    "    if CLIP_MODEL_NAME == 'RN50':\n",
    "        MASK_THRESHOLD = 0.2\n",
    "    if CLIP_MODEL_NAME == 'RN101':\n",
    "        MASK_THRESHOLD = 0.2\n",
    "    if CLIP_MODEL_NAME == 'ViT-B/16':\n",
    "        MASK_THRESHOLD = 0.3\n",
    "    if CLIP_MODEL_NAME == 'ViT-B/32':\n",
    "        MASK_THRESHOLD = 0.3\n",
    "    return MASK_THRESHOLD\n",
    "\n",
    "def get_clipcam_single(clipcam, model, MASK_THRESHOLD, image, sentence = None, DISTILL_NUM = 0, ATTACK = None, GPU_ID = 'cpu'):\n",
    "    image = image\n",
    "    orig_image = image\n",
    "    image = ImageTransform(image)\n",
    "    orig_image = originalTransform(orig_image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(GPU_ID)\n",
    "    orig_image = orig_image.to(GPU_ID)\n",
    "\n",
    "    if sentence == None:\n",
    "        sentence = input(f\"Please enter the query sentence: \")\n",
    "    text  = clip_modified.tokenize(sentence)\n",
    "    text = text.to(GPU_ID)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    grayscale_cam = clipcam(input_tensor=image, text_tensor=text_features)[0, :]\n",
    "    grayscale_cam_total = grayscale_cam[np.newaxis, :]\n",
    "\n",
    "    grayscale_cam_mask = np.where(grayscale_cam_total < MASK_THRESHOLD, 0, 1)\n",
    "    pred_bbox, pred_mask = MaskToBBox(grayscale_cam_mask, 1)\n",
    "    final_img = getHeatMapOneBBox(grayscale_cam, orig_image.permute(1, 2, 0).cpu().numpy(), pred_bbox, sentence)\n",
    "    #final_img = getHeatMapNoBBox(grayscale_cam,orig_image.permute(1, 2, 0).cpu().numpy(),'test')\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--image_path\", type=str,\n",
    "                    help=\"single image path or 4 images directory (grid)\")\n",
    "parser.add_argument(\"--gpu_id\", type=str, default='cpu',\n",
    "                    help=\"GPU id to work on, \\'cpu\\'.\")\n",
    "parser.add_argument(\"--clip_model_name\", type=str,\n",
    "                    default='ViT-B/16', help=\"Model name of CLIP\")\n",
    "parser.add_argument(\"--cam_model_name\", type=str,\n",
    "                    default='GradCAM', help=\"Model name of GradCAM\")\n",
    "parser.add_argument(\"--resize\", type=int,\n",
    "                    default=1, help=\"Resize image or not\")\n",
    "parser.add_argument(\"--distill_num\", type=int, default=0,\n",
    "                    help=\"Number of iterative masking\")\n",
    "parser.add_argument(\"--attack_type\", type=str, default=None,\n",
    "                    help=\"attack type: \\\"snow\\\", \\\"fog\\\"\")\n",
    "parser.add_argument(\"--sentence\", type=str, default='',\n",
    "                    help=\"input text\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.gpu_id != 'cpu':\n",
    "    args.gpu_id = int(args.gpu_id)\n",
    "\n",
    "if os.path.isfile(args.image_path):\n",
    "    img = Image.open(args.image_path)\n",
    "    images = [img]\n",
    "else:\n",
    "    images = []\n",
    "    for f in os.listdir(args.image_path):\n",
    "        images.append(Image.open(os.path.join(args.image_path, f)))\n",
    "\n",
    "final_img = clipcam(args.clip_model_name, args.cam_model_name, images, args.sentence, args.distill_num, args.attack_type, args.gpu_id)\n",
    "final_img.save('clipcam_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
